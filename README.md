# MuseGAN: Multi-track Sequential Generative Adversarial Networks for Symbolic Music Generation and Accompaniment

This project implements the MuseGAN model using TensorFlow for generating musical sequences.

## Description

The MuseGAN model, proposed in the paper "MuseGAN: Multi-track Sequential Generative Adversarial Networks for Symbolic Music Generation and Accompaniment" (Dong et al., 2017), employs multi-track sequential generative adversarial networks to create multi-track musical compositions, such as melody, accompaniment, etc.

This project provides an implementation of the MuseGAN model in Python using the TensorFlow framework. It includes code for training the model as well as an example of using the model to generate musical sequences.

## Usage

1. **Install Dependencies**

   Make sure you have all the required dependencies installed by running.

2. **Prepare Data**

Prepare your musical sequence data in MIDI format. You can use any dataset or create your own. Ensure your data is organized according to the expected structure.

3. **Train the Model**

Run the training script, providing the path to your data [link](https://github.com/InnaKoles/final-muzgan/blob/main/Train_Model).

4. **Generate Musical Sequences**

Use the trained model to generate new musical sequences [link](https://github.com/InnaKoles/final-muzgan/blob/main/Use%20model)

## References

- Paper "MuseGAN: Multi-track Sequential Generative Adversarial Networks for Symbolic Music Generation and Accompaniment" (Dong et al., 2017): [Link](https://arxiv.org/abs/1709.06298)
- Official repository of MuseGAN by the authors: [Link](https://github.com/salu133445/musegan)
